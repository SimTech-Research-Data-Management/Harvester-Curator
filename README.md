# darus_data_harvester small examples:

- **crawler.py** can identify all file types in a repository and group them accordingly
- **harvester.py** collects metadata and puts ina json file
- **Documentation** https://docs.google.com/document/d/1-nOwCnVz_3FDLZ1XSMEO-h1dI1eTbXqqxKMkziwOfLM/edit
